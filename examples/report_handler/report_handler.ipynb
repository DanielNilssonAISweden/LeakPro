{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d5acad-514e-4950-94a0-c80d789d9364",
   "metadata": {},
   "source": [
    "# Report handler examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5dbe9",
   "metadata": {},
   "source": [
    "Install leakpro as ``` pip install -e /path/to/leakpro ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b48ce8",
   "metadata": {},
   "source": [
    "### Synthetic examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf529c7-8bfe-49da-9889-59111ec2cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from leakpro.synthetic_data_attacks.anomalies import return_anomalies\n",
    "from leakpro.synthetic_data_attacks.inference_utils import inference_risk_evaluation\n",
    "from leakpro.synthetic_data_attacks.linkability_utils import linkability_risk_evaluation\n",
    "from leakpro.synthetic_data_attacks.singling_out_utils import singling_out_risk_evaluation\n",
    "\n",
    "#Get ori and syn\n",
    "n_samples = 100\n",
    "DATA_PATH = \"../synthetic_data/datasets/\"\n",
    "ori = pd.read_csv(os.path.join(DATA_PATH, \"adults_ori.csv\"), nrows=n_samples)\n",
    "syn = pd.read_csv(os.path.join(DATA_PATH, \"adults_syn.csv\"), nrows=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c89f3738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done   2 out of  64 | elapsed:    1.2s remaining:   38.1s\n",
      "[Parallel(n_jobs=64)]: Done  64 out of  64 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predictions (array([-1,  1]), array([ 3, 97]))\n",
      "Syn anom shape (3, 14)\n"
     ]
    }
   ],
   "source": [
    "syn_anom = return_anomalies(df=syn, n_estimators=1000, n_jobs=-1, verbose=True)\n",
    "print(\"Syn anom shape\",syn_anom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad69ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a singling-out result\n",
    "sin_out_res = singling_out_risk_evaluation(\n",
    "    dataset = \"adults\",\n",
    "    ori = ori,\n",
    "    syn = syn_anom,\n",
    "    n_attacks = syn_anom.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d7ffb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linkability result\n",
    "link_res = linkability_risk_evaluation(\n",
    "    dataset = \"adults\",\n",
    "    ori = ori,\n",
    "    syn = syn_anom,\n",
    "    n_samples = syn_anom.shape[0],\n",
    "    n_attacks = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5c20e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create base-case inference result\n",
    "inf_res = inference_risk_evaluation(\n",
    "    dataset = \"adults\",\n",
    "    ori = ori,\n",
    "    syn = syn_anom,\n",
    "    worst_case_flag = False,\n",
    "    n_attacks = syn_anom.shape[0]\n",
    ")\n",
    "\n",
    "# # Create worst-case inference result\n",
    "inf_res_worst = inference_risk_evaluation(\n",
    "    dataset = \"adults\",\n",
    "    ori = ori,\n",
    "    syn = syn_anom,\n",
    "    worst_case_flag = True,\n",
    "    n_attacks = syn_anom.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3be474",
   "metadata": {},
   "source": [
    "### Gradient inversion example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35aee5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 15:37:19,407 INFO     Inverting gradient initialized.\n",
      "2024-12-10 15:37:21,549 INFO     Iteration 0, loss 0.00017312286945525557\n",
      "2024-12-10 15:37:21,558 INFO     New best loss: 0.00017312286945525557 on round: 0\n",
      "2024-12-10 15:37:21,716 INFO     New best loss: 0.00015130748215597123 on round: 1\n",
      "2024-12-10 15:37:21,865 INFO     New best loss: 0.00014282172196544707 on round: 2\n",
      "2024-12-10 15:37:22,004 INFO     New best loss: 0.0001371056423522532 on round: 3\n",
      "2024-12-10 15:37:22,146 INFO     New best loss: 0.00013112256419844925 on round: 4\n",
      "2024-12-10 15:37:22,404 INFO     New best loss: 0.00012842075375374407 on round: 6\n",
      "2024-12-10 15:37:22,531 INFO     New best loss: 0.00012392438657116145 on round: 7\n",
      "2024-12-10 15:37:22,661 INFO     New best loss: 0.00011872354662045836 on round: 8\n",
      "2024-12-10 15:37:22,915 INFO     New best loss: 0.00011686021025525406 on round: 10\n",
      "2024-12-10 15:37:23,045 INFO     New best loss: 0.00011540275590959936 on round: 11\n",
      "2024-12-10 15:37:23,176 INFO     New best loss: 0.00010958370694424957 on round: 12\n",
      "2024-12-10 15:37:23,306 INFO     New best loss: 0.00010606442810967565 on round: 13\n",
      "2024-12-10 15:37:23,432 INFO     New best loss: 0.00010551762534305453 on round: 14\n",
      "2024-12-10 15:37:23,558 INFO     New best loss: 0.00010321227455278859 on round: 15\n",
      "2024-12-10 15:37:23,688 INFO     New best loss: 0.00010049617412732914 on round: 16\n",
      "2024-12-10 15:37:23,819 INFO     New best loss: 9.98983159661293e-05 on round: 17\n",
      "2024-12-10 15:37:24,073 INFO     New best loss: 9.980545291909948e-05 on round: 19\n",
      "2024-12-10 15:37:24,330 INFO     New best loss: 9.797140228329226e-05 on round: 21\n",
      "2024-12-10 15:37:24,457 INFO     New best loss: 9.713656618259847e-05 on round: 22\n",
      "2024-12-10 15:37:29,775 INFO     New best loss: 9.707298158900812e-05 on round: 63\n",
      "2024-12-10 15:37:31,176 INFO     New best loss: 9.695763583295047e-05 on round: 75\n",
      "2024-12-10 15:37:31,299 INFO     New best loss: 9.695166954770684e-05 on round: 76\n",
      "2024-12-10 15:37:31,425 INFO     New best loss: 9.689731814432889e-05 on round: 77\n",
      "/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:70: FutureWarning: Importing `peak_signal_noise_ratio` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `peak_signal_noise_ratio` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n"
     ]
    }
   ],
   "source": [
    "from gia_utils.cifar import get_cifar10_loader\n",
    "from gia_utils.model import ResNet\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "\n",
    "from leakpro.attacks.gia_attacks.invertinggradients import InvertingConfig\n",
    "from leakpro.fl_utils.gia_train import train\n",
    "from leakpro.run import run_inverting\n",
    "\n",
    "model = ResNet(BasicBlock, [5, 5, 5], num_classes=10, base_width=16 * 10)\n",
    "client_dataloader, data_mean, data_std = get_cifar10_loader(num_images=1, batch_size=1, num_workers=2)\n",
    "\n",
    "# Meta train function designed to work with GIA\n",
    "train_fn = train\n",
    "\n",
    "# Baseline config\n",
    "configs = InvertingConfig()\n",
    "configs.at_iterations = 80 # Decreased from 8000 to avoid GPU memory crash\n",
    "\n",
    "name = \"my_gia_results\"\n",
    "GIA_result = run_inverting(model, client_dataloader, train_fn, data_mean, data_std, configs, experiment_name=name, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e8caa",
   "metadata": {},
   "source": [
    "### Membership Inference Attack, CIFAR example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d38d6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45a0d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from mia_utils.utils.cifar_data_preparation import get_cifar_dataloader\n",
    "from mia_utils.utils.cifar_model_preparation import ResNet18, create_trained_model_and_metadata\n",
    "\n",
    "\n",
    "# Load the config.yaml file\n",
    "with open('mia_utils/train_config.yaml', 'r') as file:\n",
    "    train_config = yaml.safe_load(file)\n",
    "\n",
    "# Generate the dataset and dataloaders\n",
    "path = os.path.join(os.getcwd(), train_config[\"data\"][\"data_dir\"])\n",
    "\n",
    "train_loader, test_loader = get_cifar_dataloader(path, train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cda80cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Training Progress: 100%|██████████| 3/3 [00:13<00:00,  4.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "if not os.path.exists(\"target\"):\n",
    "    os.makedirs(\"target\")\n",
    "if train_config[\"data\"][\"dataset\"] == \"cifar10\":\n",
    "    num_classes = 10\n",
    "elif train_config[\"data\"][\"dataset\"] == \"cifar100\":\n",
    "    num_classes = 100\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset name\")\n",
    "\n",
    "model = ResNet18(num_classes = num_classes)\n",
    "train_acc, train_loss, test_acc, test_loss = create_trained_model_and_metadata(model, \n",
    "                                                                               train_loader, \n",
    "                                                                               test_loader, \n",
    "                                                                               train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872bf51",
   "metadata": {},
   "source": [
    "##### Run the MIA attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f28eb14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 15:37:48,180 INFO     Target model blueprint created from ResNet18 in ./mia_utils/utils/cifar_model_preparation.py.\n",
      "2024-12-10 15:37:48,183 INFO     Loaded target model metadata from ./target/model_metadata.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audit': {'random_seed': 1234, 'attack_list': {'population': {'attack_data_fraction': 1.0}}, 'output_dir': './leakpro_output', 'attack_type': 'mia', 'modality': 'image'}, 'target': {'module_path': './mia_utils/utils/cifar_model_preparation.py', 'model_class': 'ResNet18', 'target_folder': './target', 'data_path': './data/cifar10.pkl'}, 'shadow_model': None, 'distillation_model': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 15:37:48,394 INFO     Loaded target model from ./target\n",
      "2024-12-10 15:37:49,289 INFO     Loaded population dataset from ./data/cifar10.pkl\n",
      "2024-12-10 15:37:49,290 INFO     Loaded population dataset from ./data/cifar10.pkl\n",
      "2024-12-10 15:37:49,291 INFO     Creating shadow model handler singleton\n",
      "2024-12-10 15:37:49,294 INFO     Creating distillation model handler singleton\n",
      "2024-12-10 15:37:49,296 INFO     Configuring the Population attack\n",
      "2024-12-10 15:37:49,297 INFO     Added attack: population\n",
      "2024-12-10 15:37:49,298 INFO     Preparing attack: population\n",
      "2024-12-10 15:37:49,299 INFO     Preparing attack data for training the Population attack\n",
      "2024-12-10 15:37:49,306 INFO     Subsampling attack data from 24000 points\n",
      "2024-12-10 15:37:49,307 INFO     Number of attack data points after subsampling: 24000\n",
      "2024-12-10 15:37:49,308 INFO     Computing signals for the Population attack\n",
      "Getting loss for model 1/ 1: 100%|██████████| 750/750 [00:12<00:00, 60.59it/s]\n",
      "2024-12-10 15:38:01,752 INFO     Running attack: population\n",
      "2024-12-10 15:38:01,758 INFO     Running the Population attack on the target model\n",
      "Getting loss for model 1/ 1: 100%|██████████| 1125/1125 [00:17<00:00, 63.04it/s]\n",
      "2024-12-10 15:38:19,692 INFO     Attack completed\n",
      "2024-12-10 15:38:19,703 INFO     Finished attack: population\n",
      "2024-12-10 15:38:19,703 INFO     Preparing results for attack: population\n",
      "2024-12-10 15:38:19,704 INFO     Auditing completed\n"
     ]
    }
   ],
   "source": [
    "from mia_utils.cifar_handler import CifarInputHandler\n",
    "\n",
    "from leakpro import LeakPro\n",
    "\n",
    "# Read the config file\n",
    "config_path = \"mia_utils/audit.yaml\"\n",
    "\n",
    "# Prepare leakpro object\n",
    "leakpro = LeakPro(CifarInputHandler, config_path)\n",
    "\n",
    "# Run the audit \n",
    "mia_results = leakpro.run_audit(return_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "373dcc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 15:38:19,719 INFO     Initializing report handler...\n",
      "2024-12-10 15:38:19,719 INFO     report_dir set to: ./leakpro_output/results\n",
      "2024-12-10 15:38:19,720 INFO     Saving results for singling_out\n",
      "2024-12-10 15:38:21,860 INFO     Saving results for linkability_risk\n",
      "2024-12-10 15:38:23,763 INFO     Saving results for inference_risk_base\n",
      "2024-12-10 15:38:28,190 INFO     Saving results for inference_risk_worst\n",
      "2024-12-10 15:38:30,418 INFO     Saving results for gia\n",
      "2024-12-10 15:38:30,431 INFO     Saving results for population\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3300x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3300x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3300x2100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3300x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "# Import and initialize ReportHandler\n",
    "from leakpro.reporting.report_handler import ReportHandler\n",
    "\n",
    "# Set report_dir to \"./leakpro_output/results\" to the results to a local results folder\n",
    "#    or don't use the report_dir argument to let the ReportHandler find an already\n",
    "#    existing results folder\n",
    "report_handler = ReportHandler(report_dir=\"./leakpro_output/results\")\n",
    "\n",
    "# # Save Synthetic results using the ReportHandler\n",
    "report_handler.save_results(attack_name=\"singling_out\", result_data=sin_out_res)\n",
    "report_handler.save_results(attack_name=\"linkability_risk\", result_data=link_res)\n",
    "report_handler.save_results(attack_name=\"inference_risk_base\", result_data=inf_res)\n",
    "report_handler.save_results(attack_name=\"inference_risk_worst\", result_data=inf_res_worst)\n",
    "\n",
    "# # Save GIA results using report handler\n",
    "report_handler.save_results(attack_name=\"gia\", result_data=GIA_result)\n",
    "\n",
    "# Save MIA resuls using report handler\n",
    "for res in mia_results:\n",
    "    report_handler.save_results(attack_name=res.attack_name, result_data=res, config=res.configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d91c7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 15:38:59,171 INFO     PDF compiled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1920x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3300x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3300x2100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3300x2100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3300x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the ReportHandler and load all the saved results\n",
    "report_handler.load_results()\n",
    "\n",
    "# Create results and collect corresponding latex texts\n",
    "report_handler.create_results_all()\n",
    "\n",
    "# Create the report by compiling the latex text\n",
    "report_handler.create_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
